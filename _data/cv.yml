- title: General Information
  type: map
  contents:
    - name: Full Name
      value: Seyedhamidreza Mousavi
    - name: Location
      value: Västerås, Sweden
    - name: Languages
      value: English (Professional), Persian (Native)
    - name: Email
      value: seyedhamidreza.mousavi@mdu.se
    - name: GitHub
      value: <a href="https://github.com/hamidmousavi0">hamidmousavi0</a>
    - name: Website
      value: <a href="https://hamidmousavi0.github.io">hamidmousavi0.github.io</a>

- title: Summary
  type: text
  contents: >
    Applied Machine Learning Researcher and Engineer with over 5 years of experience
    in efficient and robust deep learning. Specialized in model compression,
    Neural Architecture Search (NAS), robustness, and fault-tolerant learning,
    with strong hands-on expertise in PyTorch, distributed training, and MLOps.
    Proven track record of translating research into real-world deployments on
    GPUs, FPGAs, and microcontrollers for safety-critical and resource-constrained systems.

- title: Education
  type: time_table
  contents:
    - title: PhD in Computer Science
      institution: Mälardalen University, Västerås, Sweden
      year: 2022 – Present
      description:
        - Research focus on efficient, compact, robust, and reliable deep neural networks.
        - Emphasis on automatic model design (NAS) for safety-critical systems and autonomous driving.
        - Thesis:Efficient Design and Training of Compact and Robust Deep Neural Networks

    - title: MSc & BSc in Computer Engineering
      institution: Shahid Bahonar University, Kerman, Iran
      year: 2012 – 2019
      description:
        - Master’s thesis on reliability and security analysis of deep learning models.
        - Bachelor’s thesis on ARM7-TDMI implementation on Xilinx FPGA.

- title: Experience
  type: time_table
  contents:
    - title: PhD Researcher – Efficient & Robust Deep Learning
      institution: Mälardalen University, Sweden
      year: 2022 – Present
      description:
        - Lead research on efficient and reliable deep learning for edge and embedded systems.
        - Developed one-shot NAS frameworks with knowledge distillation, achieving up to 60× reduction in search cost.
        - Designed fault-tolerant activation functions improving resilience under hardware bit-flip errors.
        - Deployed TinyDL models on STM32 microcontrollers using TinyEngine.
        - Mentored junior researchers and contributed to teaching in Deep Learning and Embedded Systems courses.

    - title: Machine Learning Researcher (Remote)
      institution: Simon Fraser University, Canada
      year: 2020 – 2022
      description:
        - Contributed to ICCAD 2020 work on aging-aware delay modeling using neural networks.
        - Conducted research on fault injection and adversarial robustness of hardware-protected DNNs.
        - Co-authored publications on stealthy bit-flip attacks and reliability-aware ML models.

- title: Open Source Projects
  type: time_table
  contents:
    - title: <a href="https://github.com/hamidmousavi0/reliable-relu-toolbox">RReLU</a>
      year: 2024
      description:
        - Reliable ReLU Toolbox for improving the resilience of deep neural networks under hardware faults.

    - title: <a href="https://github.com/hamidmousavi0/ProARD">ProARD</a>
      year: 2025
      description:
        - Progressive Adversarial Robustness Distillation framework for training compact and robust models.

- title: Skills
  type: list
  contents:
    - <b>Machine Learning & AI:</b> Efficient AI, Model Compression, NAS, Pruning, Quantization, Robustness, Fault Tolerance
    - <b>Frameworks:</b> PyTorch, HuggingFace, LangGraph, TensorRT
    - <b>Distributed & MLOps:</b> DDP, Horovod, Docker, DVC, Git, Google Vertex AI, GCP
    - <b>Programming:</b> Python, C/C++, VHDL, LaTeX
    - <b>Embedded & Hardware:</b> FPGA (Vivado), STM32, NVIDIA Jetson
    - <b>Soft Skills:</b> Problem-solving, simplifying complex systems, cross-disciplinary collaboration, mentoring

- title: Selected Publications
  type: list
  contents:
    - ProARD:Progressive Adversarial Robustness Distillation, IJCNN 2025
    - DASS:Differentiable Architecture Search for Sparse Neural Networks, TECS 2023
    - TAS:Ternarized NAS for Resource-Constrained Edge Devices, DATE 2022
    - Aadam:Aging-Aware Cell Library Delay Modeling, ICCAD 2020
